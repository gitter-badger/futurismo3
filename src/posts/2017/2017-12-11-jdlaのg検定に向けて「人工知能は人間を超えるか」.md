---
title: JDLAのG検定に向けて「人工知能は人間を超えるか」で対策
author: admin
type: post
date: 2017-12-10T17:02:39+00:00
excerpt: JDLAのG検定に向けて「人工知能は人間を超えるか」で対策
draft: true
private: true
url: /archives/=6828
pvc_views:
  - 18
pdrp_attributionLocation:
  - end
page_layout:
  - def
title_view:
  - 'y'
follow:
  - follow
index:
  - index
fullscreen_view:
  - 'n'
side:
  - 'y'
menu_view:
  - 'y'
dsq_thread_id:
  - 6341103559
categories:
  - 機械学習
  - 資格
tags:
  - DeepLearning

---
JDLA(日本ディープラーニング協会)のG検定というのが12/16(土)に実施される。
  
遅ればせながらツイッターに流れてきて試験日を知り、12/4日に申し込んでみた。

課題図書である「人工知能は人間を超えるか」の要点をシラバスにマッピングしながら、試験対策をしてみることにした。

## シラバス(2017/12) {#-2017-12-}

  * 人工知能（AI）とは（人工知能の定義）
  * 人工知能をめぐる動向 
      * 探索・推論、知識表現、機械学習、深層学習
  * 人工知能分野の問題 
      * トイプロブレム、フレーム問題、弱いAI、強いAI、身体性、シンボルグラウンディング問題、特徴量設計、チューリングテスト、シンギュラリティ
  * 機械学習の具体的手法 
      * 代表的な手法、データの扱い、応用
  * ディープラーニングの概要 
      * ニューラルネットワークとディープラーニング、既存のニューラルネットワークにおける問題、ディープラーニングのアプローチ、CPU と GPU
      * ディープラーニングにおけるデータ量
  * ディープラーニングの手法 
      * 活性化関数、学習率の最適化、更なるテクニック、CNN、RNN
      * 深層強化学習、深層生成モデル
  * ディープラーニングの研究分野 
      * 画像認識、自然言語処理、音声処理、ロボティクス （強化学習）、マルチモーダル
  * ディープラーニングの応用に向けて 
      * 産業への応用、法律、倫理、現行の議論

## 〜虎の巻〜 {#-}

### 人工知能とは {#-}

  * &#8220;人間のように考えるコンピュータ&#8221; -> これはできていない
  * &#8220;人間の知的な活動の一面を真似している技術&#8221; -> これはできている&#8221;チューリングマシン&#8221; -> 計算可能なことは、すべてコンピュータで実現できる。よって人間の思考はプログラムで実現できるという考え方。 
    構成論的な理解と分析的な理解がある。人工知能研究者は構成的に理解したいとしているのに対し、脳科学者は分析的に知能を理解したいと望んでいる。
    
    ロボットと人工知能は違う。ロボットの脳に当たるのが人工知能。
    
    &#8220;AI効果&#8221; -> かつて人工知能と呼ばれていたが、実用化され、ひとつの分野を構成すると、人工知能と呼ばれなくなる。</li> </ul> 
    
    #### 4つのレベル {#4-}
    
      * Level1: 単純な制御プログラム
  
        制御工学、システム工学。
      * Level2: 古典的な人工知能
  
        振る舞いのパターンが極めて多彩なもの。入力と出力を関係づける方法が洗練されていて、入力と出力の組み合わせの数が極端に多いもの。推論・探索を取り入れていたり、知識ベースを入れていたりする。
      * Level3: 機械学習を取り入れた人工知能
  
        推論の仕組みや知識ベースが、データを元に学習されたもので、典型的には機械学習のアルゴリズムが利用されている場合が多い。パターン認識という古くからの研究をベースに1990から進展し、2000年代に飛躍した。
      * Level4:ディープラーニングを取り入れた人工知能
  
        機械学習をする際のデータを表すために使われる変数自体を学習するもの。
    
    ### 人工知能をめぐる動向 {#-}
    
    #### 探索・推論 第一次AIブーム {#-ai-}
    
    探索木を構築し、どんどん掘り下げていくと、いつか目的とする条件が現れる。
  
    探索木とは、要するに場合分けのこと。探索木を探索する方法は２つある。
    
      * 深さ優先探索 &#8230; とにかく行けるところまで掘り下げてみて、ダメなら次の枝葉に移る。
      * 幅優先探索 &#8230; 同じ階層をしらみつぶしにあたってから次の階層に進む。オセロやチェス、将棋、囲碁などのゲームにも探索が用いられる。盤面の起こりうる組み合わせが膨大なため、しらみつぶしに調べることはできない。そこで、盤面を評価するスコアをつくり、そのスコアがよくなるように、次の指し手を探索することになる。それが現在まで続くゲーム攻略のための人工知能の基本的な設計。
    
    #### 知識表現 第２次AIブーム {#-ai-}
    
    第２次AIブームを支えたのは知識。
    
    1964年に開発されたイライザという対話システムは、コンピュータと人がテキストデータでやり取りして、あたかも「対話」しているように見えるシステム。簡単なルールベースのやり取りをしているだけ。
    
    エキスパートシステムが第二次AIブームの主役。ある専門領域の知識を取り込み、推論を行うことで、その分野のエキスパートのように振る舞うプログラム。マイシンが有名。
    
    エキスパートシステムの問題の一つは、コンピュータに知識を与えるために、専門家からヒアリングをして知識を取り出さないといけない。知識の数が増えて、ルールの数が数千、数万となると、お互いに矛盾していたり、一貫していなかったりするので、知識を適切に維持管理する必要が出てくることもわかった。さらち、高度な専門知識が必要な限定された分野ではよくても、より広範囲の知識を扱おうとすると、とたんに知識を記述するのが難しくなった。
    
    オントロジー研究・・・知識を正しく記述するための研究。知識を記述するのが難しいことがわかってくると、知識を記述すること自体に対する研究が行われるようになってきた。
    
    人間がきちんと考えて知識を記述していくためにはどうしたらよいかを考えるのがヘビーウェイトオントロジー。
    
    コンピュータにデータを読み込ませて自動で概念缶の関係性を見つけようというのかライトウェイトオントロジー。ワトソンが有名。
    
    知識を書くということは、予想以上に大変で、なかなか書ききれない。悲観的な観測が広がり、1995年ごろから、再びAIは冬の時代を迎えてしまう。
    
    第２次ＡＩブームでは「知識」をたくさん入れれば、それらしく振る舞うことは できたが、基本的に入力した知識以上のことはできない。そして、入力する知識は、より実用に耐えるもの、 例外にも対応できるものをつくろうとするほど膨大になり、いつまでも書き終わらない。根本的には、記号とそれが意味する意味内容が結びついておらず、コンピュータにとって「意味」を扱うことはきわめて難しい。
    
    #### 機械学習 {#-}
    
    機械学習とは、人工知能のプログラム自身が学習する仕組み。学習とは、分ける処理である。人間にとっての「認識」や「判断」は、基本的に「イエス・ノー問題」として捉えることができる。この精度を上げることが、学習すること。（分類）
    
    機械学習は、コンピュータが大量のデータを処理しながらこの「分け方」を自動的に習得する。一旦分け方を習得すれば、それを使って未知のデータを分けることが出来る。
    
    機械学習は、教師あり学習と、教師なし学習にわけられる。
    
    教師あり学習は、入力と正しい出力がセットになった訓練データを予め用意して、ある入力が与えられたときに、正しい出力が出来るようにコンピュータに学習させる。
    
    教師なし学習は、入力データのみを与え、データの中に内在する構造をつかむために用いられる。ある共通項をもつクラスタにわけたり、頻出パターンを見つけたりする。
    
    機械学習では、なにを特徴量とするかは人間が決めないといけない。うまい特徴量を設計すれば機械学習はうまく動き、そうでなければ動かない。
    
    #### 深層学習 {#-}
    
    ディープラーニング。データを元にコンピュータが自ら特徴量を作り出す。人間が特徴量を設計するのではなく、コンピュータが自ら高次の特徴量を獲得し、それを元に画像を分類できるようになる。
    
    ディープラーニングが従来の機械学習とは大きく異なる点は、
    
      * １層ずつ階層ごとに学習していく点
      * オートエンコーダという情報圧縮機を用いることディープラーニングがやっていることは、
  
        主成分分析を非線形にして、多段にしただけ。
    
    ### 人工知能分野の問題 {#-}
    
    #### トイ・プロブレム {#-}
    
    おもちゃの問題。 第一次AIブームの人工知能は、非常に限定された状況でしか問題が解けなかった。現実の問題はもっとずっと複雑だった。
    
    私たちが普段直面するような本当に解きたい問題は全然解けないという、限界が明らかになり、1970年代にいったん下火になり冬の時代が訪れる。
    
    #### プランニング {#-}
    
    探索木を使って、ロボットの行動計画をつくること。
  
    あらかじめ行動計画を記述しておれば、ロボットはそれに従って行動する。
  
    前提条件と行動と結果という３つの組み合わせで記述するSTIRPSが有名。
    
    #### フレーム問題 {#-}
    
    あるタスクを実行するのに「関係ある知識だけを取り出してそれを使う」という、人間ならごく当たり前にやっている作業がいかに難しいかを示している。
    
    #### シンボルグラウンディング問題 {#-}
    
    記号（文字列・言葉）をそれぞれが意味するものと結び付けられるかどうかをとうもの。コンピュータは記号の「意味」がわかっていないので、記号をその意味するものとむすびつけることができない。
    
    #### 身体性 {#-}
    
    身体がないと、シンボルとそれが指すものを接地（グラウンドさせる）ことができない。これを身体性に着目した研究という。
    
    #### 弱いAI、強いAI {#-ai-ai}
    
    ジョン・サール氏が提唱。
    
      * 強いAI ・・・ 入力と出力を備え、適切にプログラムされたコンピュータは、人間が心を持つのと全く同じ意味で、心を持つ。
      * 弱いAI ・・・ 心をもつひつようはなく、限定された知識によって一見知的な問題解説が行えれば良いとする立場。
  
        #### チューリングテスト {#-}
        
        コンピュータと別の部屋にいる人間が画面とキーボードを通じて会話をし、その人が、相手がコンピュータと見抜けなければ合格。ローブナー賞。</li> </ul> 
        
        #### 特徴量設計 {#-}
        
        特徴量というのは、機械学習の入力に使う変数のことで、その値が対象の特徴量を定量的に表す。機械学習の弱点は、特徴量設計にある。機械学習の精度を上げるのは、どんな特徴量を入れるかにかかっているのに、それは人間が頭を使って考えるしかなかった。
        
        ### 機械学習の具体的手法 {#-}
        
        #### 最近傍法 {#-}
        
        一番近い隣を使う。一番近いデータのカテゴリが当てはまる確率が高いはずだという仮説に基づいている。
        
        #### ナイーブベイズ法 {#-}
        
        ベイズの定理を使って分ける方法、データの特徴ごとにどのカテゴリに当てはめるのか足し合わせていく。
        
        #### 決定木 {#-}
        
        ある属性がある値に入っているかどうかで線引きをする。最初に来る質問は、「情報量が多いもの」、つまり、その単語が入っているかどうかを聞くことで、どのカテゴリかがだいたいわかるものが自動的に選ばれる。
        
        #### サポートベクタマシン {#-}
        
        マージンを最大化するように分ける。
        
        ### ニューラルネットワーク {#-}
        
        人間の脳神経回路を真似することによって分けようというもの。