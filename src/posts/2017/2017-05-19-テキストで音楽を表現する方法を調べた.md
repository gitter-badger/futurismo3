---
author: admin
categories:
- 音楽
date: 2017-05-19T07:49:00+00:00
dsq_thread_id:
- 5.830878e+09
excerpt: テキストで音楽を表現する方法を調べた
follow:
- follow
fullscreen_view:
- "n"
index:
- index
menu_view:
- "y"
page_layout:
- def
pdrp_attributionLocation:
- end
pvc_views:
- 601
side:
- "y"
title: テキストで音楽を表現する方法を調べた
title_view:
- "y"
type: post
url: /archives/=6448
---

テキストで音楽を表現する方法を調べた。

char-rnn で音楽生成したい
=========================

以前の記事で、char-rnn というものを試して、
坊ちゃんのテキストからテキスト生成をすることを試した。

-   [LSTM で坊ちゃんを学習させて文章生成 |
    Futurismo](https://futurismo.biz/archives/6385)

これを音楽に応用してみたい。今回の記事はその準備として情報収集をした。

こういうテキストから LSTM
を使って音楽を生成する試みは、いろんな人がやっている。
発端となっているのは、Andrej Karpathy 氏のブログ記事。

-   [The Unreasonable Effectiveness of Recurrent Neural
    Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)
-   [リカレントニューラルネットワークの理不尽な効力（翻訳） -
    Qiita](https://qiita.com/KojiOhki/items/397f157342e0def06a9b)

Andrej Karpathy さんは、Touch で char-rnn を実装している。

-   [karpathy/char-rnn: Multi-layer Recurrent Neural Networks (LSTM,
    GRU, RNN) for character-level language models in
    Torch](https://github.com/karpathy/char-rnn)

私は最近、TensorFlow や Keras による、char-rnn の実装を勉強した。

-   Udacity DLND [deep-learning/Anna\_KaRNNa.ipynb at master ·
    udacity/deep-learning](https://github.com/udacity/deep-learning/blob/master/intro-to-rnns/Anna_KaRNNa.ipynb)
-   Fast.AI [courses/char-rnn.ipynb at master ·
    fastai/courses](https://github.com/fastai/courses/blob/master/deeplearning1/nbs/char-rnn.ipynb)

Keras が好きなので、勉強のために Keras で実装したいと考えている。

記譜法を調べた
==============

ABC 記譜法
----------

ABC 記法はわりと有名な記法。WikiPedia にも情報がある。

-   [ABC 記譜法 -
    Wikipedia](https://ja.wikipedia.org/wiki/ABC%E8%A8%98%E8%AD%9C%E6%B3%95)

以下の特徴がある。

-   アスキー文字で音楽を表現
-   関連ソフトウェアが豊富
-   民族音楽に強い

ABC 記法から、五線譜に変換して再生する OSS.abcjs. これは凄い。

-   [abcjs](https://abcjs.net/)
-   [paulrosen/abcjs: javascript for rendering abc music
    notation](https://github.com/paulrosen/abcjs)

データベース・音源集

-   [abc | tune collections](https://abcnotation.com/tunes)
-   [jukedeck/nottingham-dataset: Cleaned version of the Nottingham
    dataset](https://github.com/jukedeck/nottingham-dataset)

LSTM に応用した事例

-   [Training a Recurrent Neural Network to Compose
    Music](https://maraoz.com/2016/02/02/abc-rnn/)
-   [“ Lisl ’ s Stis ”: Recurrent Neural Networks for Folk Music
    Generation | High Noon
    GMT](https://highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation/)

\*\*kern notation
-----------------

マイナーな記法。

-   [The Humdrum \*\*kern
    Representation](https://www.music-cog.ohio-state.edu/Humdrum/representations/kern.html)

データベースにクラシック音楽の曲がたくさんあるのが魅力。

-   [KernScores](https://kern.humdrum.org/)
-   [automata/ana-music: Automatic analysis of classical music for
    generative composition](https://github.com/automata/ana-music)

ツールとしては、music21 をつかう。これは、DeepJazz でも使われている。

-   [jisungk/deepjazz: Deep learning driven jazz generation using Keras
    & Theano!](https://github.com/jisungk/deepjazz)

music21 はデータベースが充実しているけれども、データ形式が XML
形式だから char-rnn には使えないかな。

-   [music21: a Toolkit for Computer-Aided
    Musicology](https://web.mit.edu/music21/)
-   [List of Works Found in the music21 Corpus — music21
    Documentation](https://web.mit.edu/music21/doc/about/referenceCorpus.html)

LSTM に応用した事例

-   [Asking RNNs+LTSMs: What Would Mozart
    Write?](https://www.wise.io/tech/asking-rnn-and-ltsm-what-would-mozart-write)

自力で midi から text 変換
--------------------------

そういう手法もある。欲しいデータがみつからなかったら、この手も使う。

-   [SYX Files — Mido 1.2.6
    documentation](https://mido.readthedocs.io/en/latest/syx.html)
-   [midi\_to\_txt.rb](https://gist.github.com/dtinth/28916cc8bb668bd131c08c61c4b1f200)
